[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian modelling",
    "section": "",
    "text": "Welcome\nThis book is a web complement to MATH 80601A Bayesian modelling, a graduate course offered at HEC Montréal.\nThese notes are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License and were last compiled on Tuesday, August 29 2023.\nThe objective of the course is to provide a hands on introduction to Bayesian data analysis. The course will cover the formulation, evaluation and comparison of Bayesian models through examples and real-data applications."
  },
  {
    "objectID": "introduction.html#probability-and-frequency",
    "href": "introduction.html#probability-and-frequency",
    "title": "1  Bayesics",
    "section": "1.1 Probability and frequency",
    "text": "1.1 Probability and frequency\nIn classical (frequentist) parametric statistic, we treat observations \\(\\boldsymbol{Y}\\) as realizations of a distribution whose parameters \\(\\boldsymbol{\\theta}\\) are unknown. All of the information about parameters is encoded by the likelihood function.\nThe interpretation of probability in the classical statistic is in terms of long run frequency, which is why we term this approach frequentist statistic. Think of a fair die: when we state that values \\(\\{1, \\ldots, 6\\}\\) are equiprobable, we mean that repeatedly tossing the die should result, in large sample, in each outcome being realized roughly \\(1/6\\) of the time (the symmetry of the object also implies that each facet should be equally likely to lie face up). This interpretation also carries over to confidence intervals: a \\((1-\\alpha)\\) confidence interval either contains the true parameter value or it doesn’t, so the probability level \\((1-\\alpha)\\) is only the long-run proportion of intervals created by the procedure that should contain the true fixed value, not the probability that a single interval contains the true value. This is counter-intuitive to most.\nIn practice, the true value of the parameter \\(\\boldsymbol{\\theta}\\) vector is unknown to the practitioner, thus uncertain: Bayesians would argue that we should treat the latter as a random quantity rather than a fixed constant. Since different people may have different knowledge about these potential values, the prior knowledge is a form of subjective probability. For example, if you play cards, one person may have recorded the previous cards that were played, whereas other may not. They thus assign different probability of certain cards being played. In Bayesian inference, we consider \\(\\boldsymbol{\\theta}\\) as random variables to reflect our lack of knowledge about potential values taken. Italian scientist Bruno de Finetti, who is famous for the claim ``Probability does not exist’’, stated in the preface of Finetti (1974):\n\nProbabilistic reasoning — always to be understood as subjective — merely stems from our being uncertain about something. It makes no difference whether the uncertainty relates to an unforseeable future, or to an unnoticed past, or to a past doubtfully reported or forgotten: it may even relate to something more or less knowable (by means of a computation, a logical deduction, etc.) but for which we are not willing or able tho make the effort; and so on […] The only relevant thing is uncertainty — the extent of our knowledge and ignorance. The actual fact of whether or not the events considered are in some sense determined, or known by other people, and so on, is of no consequence.\n\nOn page 3, de Finetti continues (Finetti 1974)\n\nonly subjective probabilities exist — i.e., the degree of belief in the occurrence of an event attributed by a given person at a given instant and with a given set of information."
  },
  {
    "objectID": "introduction.html#posterior-distribution",
    "href": "introduction.html#posterior-distribution",
    "title": "1  Bayesics",
    "section": "1.2 Posterior distribution",
    "text": "1.2 Posterior distribution\nWe consider a parametric model with parameters \\(\\boldsymbol{\\theta}\\) defined on \\(\\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p\\). In Bayesian learning, we adjoin to the likelihood \\(\\mathcal{L}(\\boldsymbol{\\theta}; \\boldsymbol{y}) \\equiv p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\) a prior function \\(p(\\boldsymbol{\\theta})\\) that reflects the prior knowledge about potential values taken by the \\(p\\)-dimensional parameter vector, before observing the data \\(\\boldsymbol{y}\\). The prior makes \\(\\boldsymbol{\\theta}\\) random and the distribution of the parameter reflects our uncertainty about the true value of the model parameters.\nIn a Bayesian analysis, observations are random variables but inference is performed conditional on the observed sample values. By Bayes’ theorem, our target is therefore the posterior density \\(p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\), defined as\n\\[\n\\underbracket[0.25pt]{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})}_{\\text{posterior}} = \\frac{\\overbracket[0.25pt]{p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}} \\times  \\overbracket[0.25pt]{p(\\boldsymbol{\\theta})}^{\\text{prior}}}{\\underbracket[0.25pt]{\\int p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta}}_{\\text{marginal likelihood }p(\\boldsymbol{y})}}.\n\\tag{1.1}\\]\nThe posterior \\(p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\) is proportional, as a function of \\(\\theta,\\) to the product of the likelihood and the prior function.\nFor the posterior to be proper, we need the product of the prior and the likelihood on the right hand side to be integrable as a function of \\(\\boldsymbol{\\theta}\\) over the parameter domain \\(\\boldsymbol{\\Theta}\\). The integral in the denominator, termed marginal likelihood and denoted \\(p(\\boldsymbol{y}) = \\mathsf{E}_{\\boldsymbol{\\theta}}\\{p(\\boldsymbol{y} \\mid \\boldsymbol{\\theta})\\}\\). The denominator of Equation 1.1 is a normalizing constant, making the posterior a valid density.\nIf \\(\\boldsymbol{\\theta}\\) is low dimensional, numerical integration such as quadrature methods can be used to compute the marginal likelihood.\nTo fix ideas, we consider next a simple one-parameter model where the marginal likelihood can be computed explicitly.\n\nExample 1.1 (Binomial model with beta prior) Consider a binomial likelihood with probability of success \\(p\\) and \\(n\\) trials, \\(Y \\sim \\mathsf{Bin}(n, p)\\). If we take a beta prior, \\(p \\sim \\mathsf{Be}(\\alpha, \\beta)\\) and observe \\(k\\) successes, the posterior is \\[\\begin{align*}\np(\\theta \\mid y = k) &\\propto \\binom{n}{k} p^k (1-p)^{n-k} \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)}p^{\\alpha-1} (1-p)^{\\beta-1}\n\\\\&\\stackrel{p}{\\propto} p^{k+\\alpha-1}(1-p)^{n-k+\\beta-1}\n\\end{align*}\\] and is \\[\\int_{0}^{1} p^{k+\\alpha-1}(1-p)^{n-k+\\beta-1}\\mathrm{d} p = \\frac{\\Gamma(k+\\alpha)\\Gamma(n-k+\\beta)}{\\Gamma(n+\\alpha+\\beta)},\\] a Beta function. Since we need only to keep track of the terms that are function of the parameter \\(p\\), we could recognize directly that the posterior distribution is \\(\\mathsf{Be}(k+\\alpha, n-k+\\beta)\\) and deduce the normalizing constant from there.\nIf \\(Y \\sim \\mathsf{Bin}(n, p)\\), the expected number of success is \\(np\\) and the expected number of failures \\(n(1-p)\\) and so the likelihood contribution, relative to the prior, will dominate as the sample size \\(n\\) grows.\nAnother way to see this is to track moments (expectation, variance, etc.) The Beta distribution, whose density is \\(f(x; \\alpha, \\beta) \\propto x^{\\alpha-1} (1-x)^{\\beta-1}\\), has expectation \\(\\alpha/(\\alpha+\\beta)\\) and variance \\(\\alpha\\beta/\\{(\\alpha+\\beta)^2(\\alpha+\\beta+1)\\}\\). The posterior mean is \\[\\begin{align*}\n\\mathsf{E}(p \\mid y) = w\\frac{y}{n} + (1-w) \\frac{a}{a+b},\n\\qquad w = \\frac{n}{n+a+b},\n\\end{align*}\\] a weighted average of the maximum likelihood estimator and the prior mean. We can think of the parameter \\(\\alpha\\) (respectively \\(\\beta\\)) as representing the prior number of success (resp. failures).\nFigure 1.1 shows three different posterior distributions with different beta priors: the first prior, which favors values closer to 1/2, leads to a more peaked posterior density, contrary to the second which is symmetric, but concentrated toward more extreme values near endpoints of the support. The rightmost panel is truncated: as such, the posterior is zero for any value of \\(p\\) beyond 1/2 and so the posterior mode may be close to the endpoint of the prior. The influence of such a prior will not necessarily vanish as sample size and should be avoided, unless there are compelling reasons for restricting the domain.\n\n\n\n\n\nFigure 1.1: Scaled binomial likelihood for six successes out of 14 trials, with \\(\\mathsf{Beta}(3/2, 3/2)\\) prior (left), \\(\\mathsf{Beta}(1/4, 1/4)\\) (middle) and truncated uniform on \\([0,1/2]\\) (right), with the corresponding posterior distributions.\n\n\n\n\n\n\nRemark (Proportionality). Any term appearing in the likelihood times prior function that does not depend on parameters can be omitted since they will be absorbed by the normalizing constant. This makes it useful to compute normalizing constants or likelihood ratios.\n\n\nRemark. An alternative parametrization for the beta distribution sets \\(\\alpha=\\mu \\kappa\\), \\(\\beta = (1-\\mu)\\kappa\\) for \\(\\mu \\in (0,1)\\) and \\(\\kappa&gt;0\\), so that the model is parametrized directly in terms of mean \\(\\mu\\), with \\(\\kappa\\) capturing the dispersion.\n\n\nRemark. A density integrates to 1 over the range of possible outcomes, but there is no guarantee that the likelihood function, as a function of \\(\\boldsymbol{\\theta}\\), integrates to one over the parameter domain \\(\\boldsymbol{\\Theta}\\).\nFor example, the binomial likelihood with \\(n\\) trials and \\(k\\) successes satisfies \\[\\int_0^1 \\binom{n}{k}p^k(1-p)^{n-k} \\mathrm{d} p = \\frac{1}{n+1}.\\]\nMoreover, the binomial distribution is discrete (supported on \\(0, \\ldots, n\\)), whereas the likelihood is continuous as a function of the probability of success, as evidenced by Figure 1.2\n\n\n\n\n\nFigure 1.2: Binomial mass function (left) and scaled likelihood function (right).\n\n\n\n\n\n\nProposition 1.1 (Sequentiality and Bayesian updating) The likelihood is invariant to the order of the observations if they are independent Thus, if we consider two blocks of observations \\(\\boldsymbol{y}_1\\) and \\(\\boldsymbol{y}_2\\) \\[p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2) = p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1) p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_2),\\] so it makes no difference if we treat data all at once or in blocks. More generally, for data exhibiting spatial or serial dependence, it makes sense to consider rather the conditional (sequential) decomposition \\[f(\\boldsymbol{y}; \\boldsymbol{\\theta}) = f(\\boldsymbol{y}_1; \\boldsymbol{\\theta}) f(\\boldsymbol{y}_2; \\boldsymbol{\\theta}, \\boldsymbol{y}_1) \\cdots f(\\boldsymbol{y}_n; \\boldsymbol{\\theta}, \\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_{n-1})\\] where \\(f(\\boldsymbol{y}_k; \\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_{k-1})\\) denotes the conditional density function given observations \\(\\boldsymbol{y}_1, \\ldots, \\boldsymbol{y}_{k-1}\\).\nBy Bayes’ rule, we can consider updating the posterior by adding terms to the likelihood, noting that \\[\\begin{align*}\np(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2) \\propto p(\\boldsymbol{y}_2 \\mid \\boldsymbol{y}_1, \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1)\n\\end{align*}\\] which amounts to treating the posterior \\(p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1)\\) as a prior. If data are exchangeable, the order in which observations are collected and the order of the belief updating is irrelevant to the full posterior. Figure 1.3 shows how the posterior becomes gradually closer to the scaled likelihood as we increase the sample size, and the posterior mode moves towards the true value of the parameter (here 0.3).\n\n\n\n\n\nFigure 1.3: Beta posterior and binomial likelihood with a uniform prior for increasing number of observations (from left to right) out of a total of 100 trials.\n\n\n\n\n\n\nExample 1.2 While we can calculate analytically the value of the normalizing constant for the beta-binomial model, we could also for arbitrary priors use numerical integration or Monte Carlo methods in the event the parameter vector \\(\\boldsymbol{\\theta}\\) is low-dimensional.\nWhile estimation of the normalizing constant is possible in simple models, the following highlights some challenges that are worth keeping in mind. In a model for discrete data (that is, assigning probability mass to a countable set of outcomes), the terms in the likelihood are probabilities and thus the likelihood becomes smaller as we gather more observations (since we multiply terms between zero or one). The marginal likelihood term becomes smaller and smaller, so it’s reciprocal is big and this can lead to arithmetic underflow.\n\nk &lt;- 6L # number of successes \nn &lt;- 14L # number of trials\nalpha &lt;- beta &lt;- 1.5 # prior parameters\nunnormalized_posterior &lt;- function(p){\n  p^(k+alpha-1) * (1-p)^(n-k + beta - 1)\n}\nintegrate(f = unnormalized_posterior,\n          lower = 0,\n          upper = 1)\n\n1.066906e-05 with absolute error &lt; 1e-12\n\n# Compare with known constant\nbeta(k + alpha, n - k + beta)\n\n[1] 1.066906e-05\n\n# Monte Carlo integration\nmean(unnormalized_posterior(runif(1e5)))\n\n[1] 1.064067e-05\n\n\n\nWhen \\(\\boldsymbol{\\theta}\\) is high-dimensional, the marginal likelihood is intractable. This is one of the main challenges of Bayesian statistics and the popularity and applicability has grown drastically with the development and popularity of numerical algorithms, following th publication of Geman and Geman (1984) and Gelfand and Smith (1990). Markov chain Monte Carlo methods circumvent the calculation of the denominator by drawing approximate samples from the posterior."
  },
  {
    "objectID": "introduction.html#posterior-predictive-distribution",
    "href": "introduction.html#posterior-predictive-distribution",
    "title": "1  Bayesics",
    "section": "1.3 Posterior predictive distribution",
    "text": "1.3 Posterior predictive distribution"
  },
  {
    "objectID": "introduction.html#summarizing-posterior-distributions",
    "href": "introduction.html#summarizing-posterior-distributions",
    "title": "1  Bayesics",
    "section": "1.4 Summarizing posterior distributions",
    "text": "1.4 Summarizing posterior distributions\nMost of the field revolves around the creation of algorithms that either circumvent the calculation of the normalizing constant (notably Monte Carlo and Markov chain Monte Carlo methods) or else provide accurate numerical approximation of the posterior pointwise, including for marginalizing out all but one parameters (integrated nested Laplace approximations, variational inference, etc.)\nThe target of inference is the whole posterior distribution, from which we can extract any summary of interest. For example, if we consider the beta-binomial model, we can assess the posterior probability \\(\\Pr(P &gt; c)\\) simply by calculating the area under the posterior density until \\(c\\). In certain settings, however it will be useful to provide moments or other characteristics of the distribution, notably since visualization of a (potentially high-dimensional) object is not easy.\nThe output of the Bayesian learning problem will be either of:\n\na fully characterized distribution\na numerical approximation to the posterior distribution (pointwise)\nan exact or approximate sample drawn from the posterior distribution\n\nPoint estimators are usually in terms of central tendency. We can return the expected value or mean of the posterior, quantiles such as the median or the mode, the value at which the posterior density is highest. These functionals may correspond to potentially different values, as shown in the left-panel of Figure 1.4. For multimodal distributions, the mode is likely the better choice.\nIf we know the distribution, we can optimize to find the mode or else return the value for the pointwise evaluation on a grid at which the density achieves it’s maximum.\n\n\n\n\n\nFigure 1.4: Point estimators from a left-skewed distribution (left) and from a multimodal distribution (right).\n\n\n\n\nOften, we will also be interested in the marginal posterior distribution of each component \\(\\theta_j\\) in turn (\\(j=1, \\ldots, p\\)). To get these, we carry out additional integration steps, \\[p(\\theta_j \\mid \\boldsymbol{y}) = \\int p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{\\theta}_{-j}.\\]\n\n\n\n\n\nFinetti, Bruno de. 1974. Theory of Probability: A Critical Introductory Treatment. Vol. 1. New York: Wiley.\n\n\nGelfand, Alan E., and Adrian F. M. Smith. 1990. “Sampling-Based Approaches to Calculating Marginal Densities.” Journal of the American Statistical Association 85 (410): 398–409. https://doi.org/10.1080/01621459.1990.10476213.\n\n\nGeman, Stuart, and Donald Geman. 1984. “Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.” IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-6 (6): 721–41. https://doi.org/10.1109/TPAMI.1984.4767596."
  },
  {
    "objectID": "priors.html#conjugate-priors",
    "href": "priors.html#conjugate-priors",
    "title": "2  Priors",
    "section": "2.1 Conjugate priors",
    "text": "2.1 Conjugate priors\nA distribution belongs to an exponential family with parameter vector \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^D\\) if it can be written as \\[\\begin{align*}\nf(y; \\boldsymbol{\\theta}) = \\exp\\left\\{ \\sum_{k=1}^K Q_k(\\boldsymbol{\\theta}) t_k(y) + D(\\boldsymbol{\\theta})\\right\\}\n\\end{align*}\\] and in particular, the support does not depend on unknown parameters. If we have an independent and identically distributed sample of observations \\(y_1, \\ldots, y_n\\), the log likelihood is thus of the form \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}) = \\sum_{k=1}^K \\phi_k(\\boldsymbol{\\theta}) \\sum_{i=1}^n t_k(y_i) + n D(\\boldsymbol{\\theta}),\n\\end{align*}\\] where the collection \\(\\sum_{i=1}^n t_k(y_i)\\) (\\(k=1, \\ldots, K\\)) are sufficient statistics and \\(\\phi_k(\\boldsymbol{\\theta})\\) are the canonical parameters. The number of sufficient statistics are the same regardless of the sample size. Exponential families play a prominent role in generalized linear models, in which the natural parameters are modelled as linear function of explanatories.\nA log prior density that is proportional to \\[\\begin{align*}\n\\log p(\\boldsymbol{\\theta}) \\propto \\eta D(\\boldsymbol{\\theta}) + \\sum_{k=1}^K Q_k(\\boldsymbol{\\theta}) \\nu_k\n\\end{align*}\\] is conjugate.\n\nExample 2.1 (Conjugate priors for the binomial model) The binomial log density with \\(y\\) successes out of \\(n\\) trials is proportional to \\[\\begin{align*}\ny \\log(p) + (n-y) \\log(1-p) = y\\log\\left( \\frac{p}{1-p}\\right) + n \\log(1-p)\n\\end{align*}\\] with canonical parameter \\(\\mathrm{logit}(p)\\), which is the natural link function for Bernoulli, giving rise to logistic regression model. The binomial distribution is thus an exponential family.\nSince the density of the binomial is of the form \\(p^y(1-p)^{n-y}\\), the beta distribution \\(\\mathsf{Be}(\\alpha, \\beta)\\) with density \\[f(x) \\propto x^{\\alpha-1} (1-x)^{\\beta-1}\\] is the conjugate prior.\n\n\nExample 2.2 (Conjugate prior for the Poisson model) The Poisson distribution with mean \\(\\mu\\) has log density proportional to \\(f(y; \\mu) \\propto y\\log(\\mu) -\\mu\\), so is an exponential family with natural parameter \\(\\log(\\mu)\\). The gamma density, \\[ f(x) \\propto \\beta^{\\alpha}/\\Gamma(\\alpha)x^{\\alpha-1} \\exp(-\\beta x)\\] with shape \\(\\alpha\\) and rate \\(\\beta\\) is the conjugate prior for the Poisson. For an \\(n\\)-sample of independent observations \\(\\mathsf{Po}(\\mu)\\) observations with \\(\\mu \\sim \\mathsf{Ga}(\\alpha, \\beta)\\), the posterior is \\(\\mathsf{Ga}(\\sum_{i=1}^n y_i + \\alpha, \\beta + n)\\).\n\n\nExample 2.3 (Posterior rates for A/B tests using conjugate Poisson model) Upworthy.com, a US media publisher, revolutionized headlines online advertisement by running systematic A/B tests to compare the different wording of headlines, placement and image and what catches attention the most. The Upworthy Research Archive (Matias et al. 2021) contains results for 22743 experiments, with a click through rate of 1.58% on average and a standard deviation of 1.23%. The clickability_test_id gives the unique identifier of the experiment, clicks the number of conversion out of impressions. See Section 8.5 of Alexander (2023) for more details about A/B testing and background information.\nConsider an A/B test from November 23st, 2014, that compared four different headlines for a story on Sesame Street workshop with interviews of children whose parents were in jail and visiting them in prisons. The headlines tested were:\n\n\nSome Don’t Like It When He Sees His Mom. But To Him? Pure Joy. Why Keep Her From Him?\nThey’re Not In Danger. They’re Right. See True Compassion From The Children Of The Incarcerated.\nKids Have No Place In Jail … But In This Case, They Totally Deserve It.\nGoing To Jail Should Be The Worst Part Of Their Life. It’s So Not. Not At All.\n\n\nAt first glance, the first and third headlines seem likely to lead to a curiosity gap. The wording of the second is more explicit (and searchable), whereas the first is worded as a question.\nWe model the conversion rate \\(\\lambda_i\\) for each headline separately using a Poisson distribution and compare the posterior distributions for all four choices. Using a conjugate prior and selecting the parameters by moment matching yields approximately \\(\\alpha = 1.64\\) and \\(\\beta = 0.01\\) for the hyperparameters.\n\n\n\n\nTable 2.1: Number of views, clicks for different headlines for the Upworthy data.\n\n\nheadline\nimpressions\nclicks\n\n\n\n\nH1\n3060\n49\n\n\nH2\n2982\n20\n\n\nH3\n3112\n31\n\n\nH4\n3083\n9\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.1: Gamma posterior for the Upworthy Sesame street headline.\n\n\n\n\nWe can visualize the posterior distributions. In this context, the large sample size lead to the dominance of the likelihood contribution \\(p(Y_i \\mid \\lambda_i) \\sim \\mathsf{Po}(n_i\\lambda_i)\\) relative to the prior. We can see there is virtually no overlap between different rates for headers H1 (preferred) relative to H4 (least favorable). The probability that Headline 3 is better than Headline 1 can be approximated by simulating samples from both posterior and computing the proportion of times one is larger: the probability of superiority is 1.7%, indicating a clear preference for the first headline H1.\n\n\nExample 2.4 (Conjugate priors in the Bayesian linear model) Consider a linear regression model with observation-specific mean \\(\\mu_i = \\mathbf{x}_i\\boldsymbol{\\beta}\\) \\((i=1,\\ldots, n)\\) with \\(\\mathbf{x}_i\\) the \\(i\\)th row of the \\(n \\times p\\) design matrix \\(\\mathbf{X}\\).\nConcatenating records, \\(\\boldsymbol{Y} \\sim \\mathsf{No}_n(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{Q}_y^{-1})\\), for a known precision matrix \\(\\mathbf{Q}_y\\), typically \\(\\mathbf{I}_n\\). To construct a conjugate joint prior for \\(p(\\boldsymbol{\\beta}, \\sigma^2)\\), we consider the sequential formulation \\[\\begin{align*}\n\\boldsymbol{\\beta} \\mid \\sigma^2 \\sim \\mathsf{No}_p(\\boldsymbol{\\nu}_\\beta, \\sigma^2 \\mathbf{Q}^{-1}_\\beta), \\qquad \\sigma^2 \\sim \\mathsf{IG}(\\alpha,\\beta)\n\\end{align*}\\] where \\(\\mathsf{IG}\\) denotes the inverse gamma distribution1\n\nThe joint posterior is Gaussian-inverse gamma and can be factorized \\[\\begin{align*}\np(\\boldsymbol{\\beta}, \\sigma^2 \\mid y) = p(\\sigma^2 \\mid y) p(\\boldsymbol{\\beta} \\mid \\sigma^2, y)\n\\end{align*}\\] where \\(p(\\sigma^2 \\mid y) \\sim \\mathsf{IG}(\\alpha^*, \\beta^*)\\) and \\(p(\\boldsymbol{\\beta} \\mid \\sigma^2, y) \\sim \\mathsf{No}_p(\\mathbf{M}\\boldsymbol{m}, \\sigma^2\\mathbf{M})\\) with \\(\\alpha^* = \\alpha + n/2\\), \\(\\beta^*=\\beta + 0.5 \\boldsymbol{\\nu}_\\beta^\\top \\mathbf{Q}_\\beta\\boldsymbol{\\nu}_\\beta + \\boldsymbol{y}^\\top\\boldsymbol{y} - \\boldsymbol{m}^\\top\\mathbf{M}\\boldsymbol{m}\\), \\(\\boldsymbol{m} = \\mathbf{Q}_\\beta \\boldsymbol{\\nu}_\\beta + \\mathbf{X}^\\top \\mathbf{Q}_y\\boldsymbol{y}\\) and \\(\\mathbf{M} = (\\mathbf{Q}_\\beta + \\mathbf{X}^\\top\\mathbf{Q}_y\\mathbf{X})^{-1}\\); the latter can be evaluated efficiently using Shermann–Morrisson–Woodbury identity.\n\nThe exponential family is quite large; Fink (1997) A Compendium of Conjugate Priors gives multiple examples of conjugate priors and work out parameter values.\n\nOne criticism of the Bayesian approach is the arbitrariness of prior functions. However, the role of the prior is often negligible in large samples (consider for example the posterior of exponential families with conjugate priors). Moreover, the likelihood is also chosen for convenience, and arguably has a bigger influence on the conclusion. Data fitted using a linear regression model seldom follow Gaussian distributions conditionally, in the same way that the linearity is a convenience (and first order approximation).\n\nIn general, unless the sample size is small and we want to add expert opinion, we may wish to pick an uninformative prior, i.e., one that does not impact much the outcome. For conjugate models, one can often show that the relative weight of prior parameters (relative to the random sample likelihood contribution) becomes negligible by investigating their relative weights."
  },
  {
    "objectID": "priors.html#uninformative-priors",
    "href": "priors.html#uninformative-priors",
    "title": "2  Priors",
    "section": "2.2 Uninformative priors",
    "text": "2.2 Uninformative priors\n\nDefinition 2.1 (Proper prior) We call a prior proper if it’s integral is finite; such prior function automatically leads to a valid posterior.\n\nThe best example of prior priors arise from probability density function. We can still employ this rule for improper priors: for example, taking \\(\\alpha, \\beta \\to 0\\) in the beta prior leads to a prior proportional to \\(x^{-1}(1-x)^{-1}\\), the integral of which diverges on the unit interval \\([0,1]\\). However, as long as the number of success and the number of failures is larger than 1, meaning \\(k \\geq 1, n-k \\geq 1\\), the posterior distribution would be proper, i.e., integrable. To find the posterior, normalizing constants are also superfluous.\nMany uninformative priors are flat, or proportional to a uniform on some subset of the real line and therefore improper. It may be superficially tempting to set a uniform prior on a large range to ensure posterior property, but the major problem is that a flat prior may be informative in a different parametrization, as the following example suggests.\n\nExample 2.5 Consider the parameter \\(\\log(\\tau) \\in \\mathbb{R}\\) and the prior \\(p( \\log \\tau) \\propto 1\\). If we reparametrize the model in terms of \\(\\tau\\), the new prior (including the Jacobian of the transformation) is \\(\\tau^{-1}\\)\n\nSome priors are standard and widely used. In location scale families with location \\(\\nu\\) and scale \\(\\tau\\), the density is such that \\[\\begin{align*}\nf(x; \\nu, \\tau) =  \\frac{1}{\\tau} f\\left(\\frac{x - \\nu}{\\tau}\\right), \\qquad \\nu \\in \\mathbb{R}, \\tau &gt;0.\n\\end{align*}\\] We thus wish to have a prior so that \\(p(\\tau) = c^{-1}p(\\tau/c)\\) for any scaling \\(c&gt;0\\), whence it follows that \\(p(\\tau) \\propto \\tau^{-1}\\), which is uniform on the log scale.\nThe priors \\(p(\\nu) \\propto 1\\) and \\(p(\\tau) \\propto \\tau^{-1}\\) are both improper but lead to location and scale invariance, hence that the result is the same regardless of the units of measurement.\n\nDefinition 2.2 (Jeffrey’s prior) In single parameter models, taking a prior function for \\(\\theta\\) proportional to the square root of the determinant of the information matrix \\(p(\\theta) \\propto \\imath(\\theta)\\) yields a prior that is invariant to parametrization, so that inferences conducted in different parametrizations are equivalent.2\n\nTo see this, consider a bijective transformation \\(\\theta \\mapsto \\vartheta\\). Under the reparametrized model and suitable regularity conditions3, the chain rule implies that \\[\\begin{align*}\ni(\\vartheta) &= - \\mathsf{E} \\left(\\frac{\\partial^2 \\ell(\\vartheta)}{\\partial^2 \\vartheta}\\right)\n\\\\&= - \\mathsf{E}\\left(\\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}\\right) \\left( \\frac{\\mathrm{d} \\theta}{\\mathrm{d} \\vartheta} \\right)^2 + \\mathsf{E}\\left(\\frac{\\partial \\ell(\\theta)}{\\partial \\theta}\\right) \\frac{\\mathrm{d}^2 \\theta}{\\mathrm{d} \\vartheta^2}\n\\end{align*}\\] Since the score has mean zero, \\(\\mathsf{E}\\left\\{\\partial \\ell(\\theta)/\\partial \\theta\\right\\}=0\\), the rightmost term vanishes. We can thus relate the Fisher information in both parametrizations, with \\[\\begin{align*}\n\\imath^{1/2}(\\vartheta) = \\imath^{1/2}(\\theta) \\left| \\frac{\\mathrm{d} \\theta}{\\mathrm{d} \\vartheta} \\right|,\n\\end{align*}\\] implying invariance.\nMost of the times, Jeffrey’s prior is improper. For the binomial model, it can be viewed as a limiting conjugate beta prior with \\(\\alpha, \\beta\\to 0\\)). Unfortunately, in multiparameter models, the system isn’t invariant to reparametrization if we consider the determinant of the Fisher information.\n\n\nExample 2.6 Consider the binomial distribution \\(f(y; \\theta, n) \\propto \\theta^y(1-\\theta)^{n-y}\\mathsf{I}_{\\theta \\in [0,1]}\\). The negative of the second derivative of the log likelihood with respect to \\(p\\) is \\[\\jmath(\\theta) = - \\partial^2 \\ell(\\theta; y) / \\partial \\theta^2 = y/\\theta^2 + (1-y)/(1-\\theta)^2\\] and since \\(\\mathsf{E}(Y)=n\\theta\\), the Fisher information is \\[\\imath = \\mathsf{E}\\{\\jmath(\\theta)\\}=n/\\theta + n/(1-\\theta) = n/\\{\\theta(1-\\theta)\\}\\] Jeffrey’s prior is thus \\(p(\\theta) \\propto \\theta^{-1}(1-\\theta)^{-1}\\).\n\n\nCheck that for the Gaussian distribution \\(\\mathsf{No}(\\mu, \\sigma^2)\\), the Jeffrey’s prior obtained by treating each parameter in turn, fixing the value of the other, are \\(p(\\mu) \\propto 1\\) and \\(p(\\sigma) \\propto 1/\\sigma\\), which also correspond to the default uninformative priors for location-scale families.\n\n\nExample 2.7 The Poisson distribution with \\(\\ell(\\lambda) \\propto -\\lambda + y\\log \\lambda\\), with second derivative \\(-\\partial^2 \\ell(\\lambda)/\\partial \\lambda^2 = y/\\lambda^2\\). Since the mean of the Poisson distribution is \\(\\lambda\\), the Fisher information is \\(\\imath(\\lambda) = \\lambda^{-1}\\) and Jeffrey’s prior is \\(\\lambda^{-1/2}\\)."
  },
  {
    "objectID": "priors.html#expert-knowledge",
    "href": "priors.html#expert-knowledge",
    "title": "2  Priors",
    "section": "2.3 Expert knowledge",
    "text": "2.3 Expert knowledge\nTh prior distribution may have parameters themselves that need to be specified by experts. One may also wish to add another layer and set an hyperprior distribution on the parameters, resulting in a hierarchical model.\nSetting parameters of priors is often done by reparametrizing the latter in terms of moments. Sometimes, it may be easier to set priors in a different scale where subject-matter expertise is most easily elicited.\n\nExample 2.8 The generalized extreme value distribution arises as the limiting distribution for the maximum of \\(m\\) independent observations. The \\(\\mathsf{GEV}(\\mu, \\sigma, \\xi)\\) distribution is a location-scale with distribution function \\[\\begin{align*}\nF(x) = \\exp\\left[ - \\left\\{1+\\xi(x-\\mu)/\\sigma\\right\\}^{-1/\\xi}_{+}\\right]\n\\end{align*}\\] where \\(x_{+} = \\max\\{0, x\\}\\).\nInverting the distribution function yields the quantile function \\[\\begin{align*}\nQ(p) \\mu + \\sigma \\frac{(-\\log p)^{-\\xi}-1}{\\xi}\n\\end{align*}\\]\nIn environmental data, we often model annual maximum. Engineering designs are often specified in terms of the \\(k\\)-year return levels, defined as the quantile of the annual maximum exceeded with probability \\(1/k\\) in any given year. Using a \\(\\mathsf{GEV}\\) for annual maximum, Coles and Tawn (1996) proposed modelling annual daily rainfall and specifying a prior on the quantile scale \\(q_1 &lt; q_2 &lt; q_3\\) for tail probabilities \\(p_1&gt; p_2 &gt; p_3\\). To deal with the ordering constraints, gamma priors are imposed on the differences \\(q_1 - o \\sim \\mathsf{Ga}(\\alpha_1, \\beta_1)\\), \\(q_2 - q_1 \\sim \\mathsf{Ga}(\\alpha_2, \\beta_2)\\) and \\(q_3-q_2 \\sim \\mathsf{Ga}(\\alpha_3, \\beta_3)\\), where \\(o\\) is the lower bound of the support. The prior is thus of the form\n\\[\\begin{align*}\np(\\boldsymbol{q}) \\propto q_1^{\\alpha_1-1}\\exp(-\\beta_1 q_1) \\prod_{i=2}^3 (q_i-q_{i-1}^{\\alpha_i-1} \\exp\\{\\beta_i(q_i-q_{i-1})\\}.\n\\end{align*}\\] where \\(0 \\leq q_1 \\leq q_2 \\leq q_3\\). We can then relate the prior parameters to moments.\nConsider the annual maximum rainfall in Abisko, Sweden.\n\n\nExample 2.9 (Prior simulation) Are the prior reasonable? One way to see this is to sample values from the priors and generate new observations.\n\n\nExample 2.10 We can specify gamma back-transform them to location \\(\\mu\\), scale \\(\\sigma\\) and shape \\(\\xi\\) and simulate observations from the \\(\\mathsf{GEV}(\\mu, \\sigma, \\xi)\\) and compare them to observations.\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Boca Raton, FL: CRC Press.\n\n\nColes, Stuart G., and Jonathan A. Tawn. 1996. “A Bayesian Analysis of Extreme Rainfall Data.” Journal of the Royal Statistical Society. Series C (Applied Statistics) 45 (4): 463–78. https://doi.org/10.2307/2986068.\n\n\nMatias, J. Nathan, Kevin Munger, Marianne Aubin Le Quere, and Charles Ebersole. 2021. “The Upworthy Research Archive, a Time Series of 32,487 Experiments in U.S. Media.” Scientific Data 8 (195). https://doi.org/10.1038/s41597-021-00934-7."
  },
  {
    "objectID": "priors.html#footnotes",
    "href": "priors.html#footnotes",
    "title": "2  Priors",
    "section": "",
    "text": "This simply means that the precision \\(\\sigma^{-2}\\), the reciprocal of the variance, has a gamma distribution with shape \\(\\alpha\\) and rate \\(\\beta\\).↩︎\nThe Fisher information is linear in the sample size for independent and identically distributed data so we can derive the result for \\(n=1\\) without loss of generality.↩︎\nUsing Bartlett’s identity; Fisher consistency can be established using the dominated convergence theorem.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alexander, Rohan. 2023. Telling Stories with Data: With Applications\nin R. Boca Raton, FL: CRC Press.\n\n\nColes, Stuart G., and Jonathan A. Tawn. 1996. “A\nBayesian Analysis of Extreme Rainfall Data.”\nJournal of the Royal Statistical Society. Series C (Applied\nStatistics) 45 (4): 463–78. https://doi.org/10.2307/2986068.\n\n\nFinetti, Bruno de. 1974. Theory of Probability: A Critical\nIntroductory Treatment. Vol. 1. New York: Wiley.\n\n\nGelfand, Alan E., and Adrian F. M. Smith. 1990. “Sampling-Based\nApproaches to Calculating Marginal Densities.” Journal of the\nAmerican Statistical Association 85 (410): 398–409. https://doi.org/10.1080/01621459.1990.10476213.\n\n\nGeman, Stuart, and Donald Geman. 1984. “Stochastic Relaxation,\nGibbs Distributions, and the Bayesian\nRestoration of Images.” IEEE Transactions on Pattern Analysis\nand Machine Intelligence PAMI-6 (6): 721–41. https://doi.org/10.1109/TPAMI.1984.4767596.\n\n\nMatias, J. Nathan, Kevin Munger, Marianne Aubin Le Quere, and Charles\nEbersole. 2021. “The Upworthy Research\nArchive, a Time Series of 32,487 Experiments in\nU.S. Media.” Scientific Data 8 (195). https://doi.org/10.1038/s41597-021-00934-7."
  }
]